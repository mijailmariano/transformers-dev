{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dependencies\n",
    "import os\n",
    "import numpy as np\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "# load data\n",
    "from datasets import load_dataset\n",
    "\n",
    "import warnings\n",
    "import re\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "# KerasNLP Training Approach\n",
    "\n",
    "### Using the KerasNLP API to train transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datasets.dataset_dict.DatasetDict"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import 'GLUE' dataset: General Language Understanding Evaluation benchmark\n",
    "# import 'CoLA' dataset: Corpus of Linguistic Acceptability\n",
    "# documentation: https://huggingface.co/datasets/glue\n",
    "\n",
    "dataset = load_dataset('glue', 'cola')\n",
    "type(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence': [\"Our friends won't buy this analysis, let alone the next one we propose.\",\n",
       "  \"One more pseudo generalization and I'm giving up.\",\n",
       "  \"One more pseudo generalization or I'm giving up.\",\n",
       "  'The more we study verbs, the crazier they get.',\n",
       "  'Day by day the facts are getting murkier.',\n",
       "  \"I'll fix you a drink.\",\n",
       "  'Fred watered the plants flat.',\n",
       "  'Bill coughed his way out of the restaurant.',\n",
       "  \"We're dancing the night away.\",\n",
       "  'Herman hammered the metal flat.',\n",
       "  'The critics laughed the play off the stage.',\n",
       "  'The pond froze solid.',\n",
       "  'Bill rolled out of the room.',\n",
       "  'The gardener watered the flowers flat.',\n",
       "  'The gardener watered the flowers.',\n",
       "  'Bill broke the bathtub into pieces.',\n",
       "  'Bill broke the bathtub.',\n",
       "  'They drank the pub dry.',\n",
       "  'They drank the pub.',\n",
       "  'The professor talked us into a stupor.'],\n",
       " 'label': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1],\n",
       " 'idx': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inspect the training data\n",
    "\n",
    "dataset[\"train\"][0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only taking the training split\n",
    "\n",
    "dataset = dataset[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''loading a tokenizing the data as NumPy arrays\n",
    "    Notes: \n",
    "        - labels consists of lists of 1s and 0s\n",
    "        - this can be converted to a NumPy array w.o. tokenizing'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b32b3e815f946c784edde99a663f57f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fe843ed279542d1bd59240b8e3437ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f43f7df5ebec4c719ecd060f0b0fff2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd63443448e2448aa5a456de47523932",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/436k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# initialize the tokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting tokenizer parameters\n",
    "\n",
    "tokenized_data = tokenizer(\n",
    "    dataset[\"sentence\"], \n",
    "    return_tensors=\"np\", \n",
    "    padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizer returns a BatchEncoding, but we convert that to a dict for Keras\n",
    "\n",
    "tokenized_data = dict(tokenized_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label field is already an array of 0s and 1s\n",
    "# convert the labels to a NumPy array\n",
    "\n",
    "labels = np.array(dataset[\"label\"])  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
